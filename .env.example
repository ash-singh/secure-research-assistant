# LM Studio API
LMSTUDIO_API_URL=http://host.docker.internal:1234/v1/chat/completions
LLM_MODEL=openai/gpt-oss-20b
CHUNK_SIZE=500
TOP_K=5
EMBEDDING_MODEL=all-MiniLM-L6-v2

# Local storagee
DATA_DIR=./data/documents
EMBEDDING_DIR=./data/embeddings
DATABASE_FILE=./data/metadata.db

# Streamlit UI
STREAMLIT_PORT=8501
STREAMLIT_ALLOW_FALLBACK=True# default toggle for LLM knowledge fallback
